{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo_PyTorch_Lightning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l1kD7omZW0p"
      },
      "source": [
        "## **TODO:** Set the value of `URL` to the URL from your learning materials"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgqnViFfZf0l"
      },
      "source": [
        "URL = None\n",
        "import os\n",
        "assert URL and (type(URL) is str), \"Be sure to initialize URL using the value from your learning materials\"\n",
        "os.environ['URL'] = URL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cefrRtm-Zh4L"
      },
      "source": [
        "%%bash\n",
        "pip install pytorch-lightning\n",
        "wget -q $URL -O ./data.zip\n",
        "mkdir -p data\n",
        "find *.zip | xargs unzip -o -d data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj8oTL4LZZXa"
      },
      "source": [
        "## Demo: PyTorch Lightining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oKWxWlmun66"
      },
      "source": [
        "import pandas as pd\n",
        "import torch as pt\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "pt.set_default_dtype(pt.float64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHnCB1E-GJPC"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "df = pd.concat(\n",
        "    pd.read_csv(file) for file in Path('data/').glob('part-*.csv')\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sASeKKBzeWMJ"
      },
      "source": [
        "working_df = df.drop('origindatetime_tr', axis = 1)\n",
        "working_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMY68kfpeY7p"
      },
      "source": [
        "test_df = working_df.sample(frac = 0.10, random_state = 42)\n",
        "test_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mm10L82eay4"
      },
      "source": [
        "train_df = working_df.drop(index = test_df.index)\n",
        "train_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vYGtKDeajQk"
      },
      "source": [
        "FEATURES = ['origin_block_latitude','origin_block_longitude','destination_block_latitude','destination_block_longitude']\n",
        "TARGET = ['fareamount']\n",
        "\n",
        "BATCH_SIZE = 2 ** 18\n",
        "PIN_MEMORY = True\n",
        "\n",
        "X_train = pt.tensor(train_df[FEATURES].values)\n",
        "X_train = X_train.pin_memory() if PIN_MEMORY else X_train\n",
        "\n",
        "y_train = pt.tensor(train_df[TARGET].values)\n",
        "y_train = y_train.pin_memory() if PIN_MEMORY else y_train\n",
        "\n",
        "train_ds = TensorDataset(y_train, X_train)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, pin_memory = PIN_MEMORY, num_workers = os.cpu_count())\n",
        "\n",
        "len(train_ds), BATCH_SIZE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCuJbfShus6a"
      },
      "source": [
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "\n",
        "class TaxiFareLinearRegressor(pl.LightningModule):\n",
        "  def __init__(self, train_dl):    \n",
        "\n",
        "    super(TaxiFareLinearRegressor, self).__init__()\n",
        "    \n",
        "    self.train_dl = train_dl\n",
        "\n",
        "    self.model = pt.nn.Linear(4, 1, bias = False)\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.model(X)\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "      y, X = batch\n",
        "\n",
        "      y_pred = self.forward(X)\n",
        "\n",
        "      loss = pt.nn.functional.mse_loss(y_pred, y)\n",
        "\n",
        "      rmse = pt.sqrt(loss)\n",
        "      \n",
        "      self.log('rmse', rmse, prog_bar=True, on_step=True, logger=True)\n",
        "\n",
        "      return loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return pt.optim.AdamW(self.parameters())\n",
        "\n",
        "  def train_dataloader(self):\n",
        "      return self.train_dl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEhKjtbec8zM"
      },
      "source": [
        "model = TaxiFareLinearRegressor(train_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcN8iAaXuw3j"
      },
      "source": [
        "from pytorch_lightning import loggers as pl_loggers\n",
        "tb_logger = pl_loggers.TensorBoardLogger('lightning_logs/')\n",
        "trainer = pl.Trainer(gpus = 1, max_epochs = 10, \n",
        "                     default_root_dir='./checkpoints',\n",
        "                     logger=tb_logger)\n",
        "trainer.fit(model) \n",
        "\n",
        "# most basic trainer, uses good defaults\n",
        "# trainer = pl.Trainer(gpus=1, progress_bar_refresh_rate=10)    \n",
        "# from pytorch_lightning.profiler import AdvancedProfiler\n",
        "# profiler = AdvancedProfiler()\n",
        "\n",
        "# trainer = pl.Trainer(gpus = 1, max_epochs = 1, profiler = True)\n",
        "# trainer = pl.Trainer(gpus = 1, max_epochs = 10, gradient_clip_val=0.5)\n",
        "# trainer = pl.Trainer(gpus = 1, max_epochs = 1, train_percent_check = 0.005, gradient_clip_val=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZodkPrFUTDg"
      },
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir lightning_logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7K0lODU3JYA"
      },
      "source": [
        "trainer.save_checkpoint('checkpoints')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY7N0HXqR0yM"
      },
      "source": [
        "with pt.no_grad():\n",
        "  print(pt.nn.functional.mse_loss(model(X_train.cuda()), y_train.cuda()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBADfsjEZ7_t"
      },
      "source": [
        "Copyright 2020 CounterFactual.AI LLC. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    }
  ]
}