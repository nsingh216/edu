{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H5yuXDh4W5zq"
   },
   "source": [
    "## **TODO:** Set the value of `URL` to the URL from your learning materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T11:15:06.196776Z",
     "start_time": "2021-02-23T11:15:06.101945Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "gk1soslgW8Xv"
   },
   "outputs": [],
   "source": [
    "URL = None\n",
    "import os\n",
    "assert URL and (type(URL) is str), \"Be sure to initialize URL using the value from your learning materials\"\n",
    "os.environ['URL'] = URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T11:15:06.199108Z",
     "start_time": "2021-02-23T11:15:06.109Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "1A_X7a8CW-UK"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget -q $URL -O ./data.zip\n",
    "mkdir -p data\n",
    "find *.zip | xargs unzip -o -d data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1-mOZ6oR8q6K"
   },
   "source": [
    "## Use PyTorch `Dataset` and `Dataloader` with a structured dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T12:01:19.415400Z",
     "start_time": "2021-02-23T12:01:17.583971Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "3oKWxWlmun66"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.data as tfd\n",
    "\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "# building blocks of our network\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4p8W9ZSL9I9w"
   },
   "source": [
    "Read the files that match `part-*.csv` from the `data` subdirectory into a Pandas data frame named `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T12:01:33.236073Z",
     "start_time": "2021-02-23T12:01:23.794741Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "I3fr0_i_YEFf"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "df = pd.concat(\n",
    "    pd.read_csv(file) for file in Path('data/').glob('part-*.csv')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6RULBK-A9X7D"
   },
   "source": [
    "## Explore the `df` data frame, including the column names, the first few rows of the dataset, and the data frame's memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T11:16:12.780900Z",
     "start_time": "2021-02-23T11:16:12.760753Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "3vDc_ZNI9ilK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fareamount</th>\n",
       "      <th>origindatetime_tr</th>\n",
       "      <th>origin_block_latitude</th>\n",
       "      <th>origin_block_longitude</th>\n",
       "      <th>destination_block_latitude</th>\n",
       "      <th>destination_block_longitude</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.87</td>\n",
       "      <td>06/01/2017 07:00</td>\n",
       "      <td>38.898314</td>\n",
       "      <td>-77.028849</td>\n",
       "      <td>38.902521</td>\n",
       "      <td>-77.030791</td>\n",
       "      <td>751d10ef2403c770a3bd4e220db8594b656d6774962b63...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.70</td>\n",
       "      <td>06/01/2017 14:00</td>\n",
       "      <td>38.904683</td>\n",
       "      <td>-77.046645</td>\n",
       "      <td>38.940181</td>\n",
       "      <td>-77.061193</td>\n",
       "      <td>a9ddc1ab38a3cc3f360e4d2408678d707658762c418e6c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.14</td>\n",
       "      <td>06/01/2017 12:00</td>\n",
       "      <td>38.910635</td>\n",
       "      <td>-77.042514</td>\n",
       "      <td>38.909652</td>\n",
       "      <td>-77.033254</td>\n",
       "      <td>1f804117b3d98193b5ab7fddc15a543a8165cd60b6b20e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.14</td>\n",
       "      <td>06/02/2017 13:00</td>\n",
       "      <td>38.889184</td>\n",
       "      <td>-77.021907</td>\n",
       "      <td>38.897207</td>\n",
       "      <td>-77.023477</td>\n",
       "      <td>21af1912855db837c7892fb073f4c59678c305aec0b23b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.32</td>\n",
       "      <td>06/01/2017 13:00</td>\n",
       "      <td>38.901336</td>\n",
       "      <td>-77.037534</td>\n",
       "      <td>38.942216</td>\n",
       "      <td>-77.073508</td>\n",
       "      <td>26dcdd256e6269e4c6f1ccd2119c345c4deed788a35082...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fareamount origindatetime_tr  origin_block_latitude  \\\n",
       "0        4.87  06/01/2017 07:00              38.898314   \n",
       "1       12.70  06/01/2017 14:00              38.904683   \n",
       "2        5.14  06/01/2017 12:00              38.910635   \n",
       "3        5.14  06/02/2017 13:00              38.889184   \n",
       "4       14.32  06/01/2017 13:00              38.901336   \n",
       "\n",
       "   origin_block_longitude  destination_block_latitude  \\\n",
       "0              -77.028849                   38.902521   \n",
       "1              -77.046645                   38.940181   \n",
       "2              -77.042514                   38.909652   \n",
       "3              -77.021907                   38.897207   \n",
       "4              -77.037534                   38.942216   \n",
       "\n",
       "   destination_block_longitude  \\\n",
       "0                   -77.030791   \n",
       "1                   -77.061193   \n",
       "2                   -77.033254   \n",
       "3                   -77.023477   \n",
       "4                   -77.073508   \n",
       "\n",
       "                                                  id  \n",
       "0  751d10ef2403c770a3bd4e220db8594b656d6774962b63...  \n",
       "1  a9ddc1ab38a3cc3f360e4d2408678d707658762c418e6c...  \n",
       "2  1f804117b3d98193b5ab7fddc15a543a8165cd60b6b20e...  \n",
       "3  21af1912855db837c7892fb073f4c59678c305aec0b23b...  \n",
       "4  26dcdd256e6269e4c6f1ccd2119c345c4deed788a35082...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T12:01:47.615284Z",
     "start_time": "2021-02-23T12:01:47.045633Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "uY4lLvmL9kne"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6368133 entries, 0 to 3289205\n",
      "Data columns (total 7 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   fareamount                   float64\n",
      " 1   origindatetime_tr            object \n",
      " 2   origin_block_latitude        float64\n",
      " 3   origin_block_longitude       float64\n",
      " 4   destination_block_latitude   float64\n",
      " 5   destination_block_longitude  float64\n",
      " 6   id                           object \n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 388.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T12:01:51.425471Z",
     "start_time": "2021-02-23T12:01:50.154182Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fareamount</th>\n",
       "      <th>origin_block_latitude</th>\n",
       "      <th>origin_block_longitude</th>\n",
       "      <th>destination_block_latitude</th>\n",
       "      <th>destination_block_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.368133e+06</td>\n",
       "      <td>6.368133e+06</td>\n",
       "      <td>6.368133e+06</td>\n",
       "      <td>6.368133e+06</td>\n",
       "      <td>6.368133e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.700529e+00</td>\n",
       "      <td>3.890408e+01</td>\n",
       "      <td>-7.702986e+01</td>\n",
       "      <td>3.890593e+01</td>\n",
       "      <td>-7.702970e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.590246e+00</td>\n",
       "      <td>1.505742e-02</td>\n",
       "      <td>1.938031e-02</td>\n",
       "      <td>1.732536e-02</td>\n",
       "      <td>2.240406e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.250000e+00</td>\n",
       "      <td>3.881206e+01</td>\n",
       "      <td>-7.711363e+01</td>\n",
       "      <td>3.881206e+01</td>\n",
       "      <td>-7.711363e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.760000e+00</td>\n",
       "      <td>3.889632e+01</td>\n",
       "      <td>-7.704237e+01</td>\n",
       "      <td>3.889667e+01</td>\n",
       "      <td>-7.704337e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.650000e+00</td>\n",
       "      <td>3.890148e+01</td>\n",
       "      <td>-7.703195e+01</td>\n",
       "      <td>3.890294e+01</td>\n",
       "      <td>-7.703156e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.162000e+01</td>\n",
       "      <td>3.890911e+01</td>\n",
       "      <td>-7.701942e+01</td>\n",
       "      <td>3.891266e+01</td>\n",
       "      <td>-7.701719e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.798300e+02</td>\n",
       "      <td>3.899422e+01</td>\n",
       "      <td>-7.691001e+01</td>\n",
       "      <td>3.899422e+01</td>\n",
       "      <td>-7.691001e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fareamount  origin_block_latitude  origin_block_longitude  \\\n",
       "count  6.368133e+06           6.368133e+06            6.368133e+06   \n",
       "mean   9.700529e+00           3.890408e+01           -7.702986e+01   \n",
       "std    4.590246e+00           1.505742e-02            1.938031e-02   \n",
       "min    3.250000e+00           3.881206e+01           -7.711363e+01   \n",
       "25%    6.760000e+00           3.889632e+01           -7.704237e+01   \n",
       "50%    8.650000e+00           3.890148e+01           -7.703195e+01   \n",
       "75%    1.162000e+01           3.890911e+01           -7.701942e+01   \n",
       "max    1.798300e+02           3.899422e+01           -7.691001e+01   \n",
       "\n",
       "       destination_block_latitude  destination_block_longitude  \n",
       "count                6.368133e+06                 6.368133e+06  \n",
       "mean                 3.890593e+01                -7.702970e+01  \n",
       "std                  1.732536e-02                 2.240406e-02  \n",
       "min                  3.881206e+01                -7.711363e+01  \n",
       "25%                  3.889667e+01                -7.704337e+01  \n",
       "50%                  3.890294e+01                -7.703156e+01  \n",
       "75%                  3.891266e+01                -7.701719e+01  \n",
       "max                  3.899422e+01                -7.691001e+01  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D-kVFhml9p0x"
   },
   "source": [
    "## Drop the `origindatetime_tr` column from the data frame. \n",
    "\n",
    "For now you are going to predict the taxi fare just based on the lat/lon coordinates of the pickup and the drop off locations. Remove the `origindatetime_tr` column from the data frame in your working dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T12:01:54.105883Z",
     "start_time": "2021-02-23T12:01:53.944896Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "jhZpJTVZaas_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6368133, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df = df.drop('origindatetime_tr', axis = 1)\n",
    "working_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6aA0NkUA_x1M"
   },
   "source": [
    "## Sample 10% of your working dataset into a test dataset data frame\n",
    "\n",
    "* **hint:** use the Pandas `sample` function with the dataframe. Specify a value for the `random_state` to achieve reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T12:01:56.584609Z",
     "start_time": "2021-02-23T12:01:56.143540Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "nsh_vPXiZr9J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(636813, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = working_df.sample(frac = 0.10, random_state = 42)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u5FschugACN-"
   },
   "source": [
    "## Drop the rows that exist in your test dataset from the working dataset to produce a training dataset.\n",
    "\n",
    "* **hint** DataFrame's `drop` function can use index values from a data frame to drop specific rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T12:02:03.829409Z",
     "start_time": "2021-02-23T12:01:58.765276Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "CT-b2IlIZ9FP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5177451, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = working_df.drop(index = test_df.index)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5R0P1sBeAX15"
   },
   "source": [
    "## Define 2 Python lists: 1st for the feature column names; 2nd for the target column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T12:02:07.834557Z",
     "start_time": "2021-02-23T12:02:07.831903Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "s62k_A-Ga-0x"
   },
   "outputs": [],
   "source": [
    "FEATURES = ['origin_block_latitude','origin_block_longitude','destination_block_latitude','destination_block_longitude']\n",
    "TARGET = ['fareamount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ttQDA-m8AgQx"
   },
   "source": [
    "## Create `X` and `y` tensors with the values of your feature and target columns in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T12:02:10.878033Z",
     "start_time": "2021-02-23T12:02:09.916890Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "hX2dlZgpbA6I"
   },
   "outputs": [],
   "source": [
    "X_train = tf.constant(train_df[FEATURES].values)\n",
    "y_train = tf.constant(train_df[TARGET].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NQm_SJFDAqqn"
   },
   "source": [
    "## Create a `TensorDataset` instance with the `y` and `X` tensors (in that order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T12:02:19.398508Z",
     "start_time": "2021-02-23T12:02:19.393660Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ffqTuheNbLpj"
   },
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_tensor_slices((X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ElrnaKEtAyEg"
   },
   "source": [
    "## Create a `DataLoader` instance specifying a custom batch size\n",
    "\n",
    "A batch size of `2 ** 18 = 262,144` should work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T12:02:20.746712Z",
     "start_time": "2021-02-23T12:02:20.741228Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "-1YyY4tgbalF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 2 ** 18\n",
    "train_ds = train_ds.batch(batch_size=BATCH_SIZE)\n",
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IA-3bXKABCW_"
   },
   "source": [
    "## Create a model using `nn.Linear`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T12:02:24.863459Z",
     "start_time": "2021-02-23T12:02:24.843786Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "6vYGtKDeajQk"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Dense(units=1, input_shape=[len(FEATURES)], activation='linear')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T12:02:27.257559Z",
     "start_time": "2021-02-23T12:02:27.252057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 5\n",
      "Trainable params: 5\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u9UvsR9gBGXj"
   },
   "source": [
    "## Create an instance of the `Adam` optimizer for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T12:02:31.233110Z",
     "start_time": "2021-02-23T12:02:31.230098Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "vPFF7EtFBKes"
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tz7LW-TnBNJu"
   },
   "source": [
    "## Declare your `loss` function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T12:02:34.169648Z",
     "start_time": "2021-02-23T12:02:34.166771Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "0T3aWJEZdiVH"
   },
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zfu2ejeoBfpQ"
   },
   "source": [
    "## Iterate over the batches returned by your `DataLoader` instance\n",
    "\n",
    "For every step of gradient descent, print out the MSE, MSE, and the batch index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T12:02:51.729396Z",
     "start_time": "2021-02-23T12:02:43.487049Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "bVjF8VYwbATZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch  1:  loss=6146.35, RMSE=78.3986\n",
      "batch  2:  loss=6035.61, RMSE=77.6892\n",
      "batch  3:  loss=5928.75, RMSE=76.9984\n",
      "batch  4:  loss=5822.18, RMSE=76.3032\n",
      "batch  5:  loss=5716.76, RMSE=75.6093\n",
      "batch  6:  loss=5612.28, RMSE=74.9151\n",
      "batch  7:  loss=5505.92, RMSE=74.2019\n",
      "batch  8:  loss=5405.74, RMSE=73.5238\n",
      "batch  9:  loss=5306.27, RMSE=72.8441\n",
      "batch 10:  loss=5246.80, RMSE=72.4348\n",
      "batch 11:  loss=5177.05, RMSE=71.9517\n",
      "batch 12:  loss=5087.61, RMSE=71.3275\n",
      "batch 13:  loss=4979.20, RMSE=70.5634\n",
      "batch 14:  loss=4846.83, RMSE=69.6192\n",
      "batch 15:  loss=4734.94, RMSE=68.8109\n",
      "batch 16:  loss=4623.94, RMSE=67.9995\n",
      "batch 17:  loss=4447.85, RMSE=66.6922\n",
      "batch 18:  loss=4467.89, RMSE=66.8422\n",
      "batch 19:  loss=4328.80, RMSE=65.7936\n",
      "batch 20:  loss=4170.72, RMSE=64.5811\n"
     ]
    }
   ],
   "source": [
    "for step, (X_train_batch, y_train_batch) in enumerate(train_ds):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # forward pass\n",
    "        y_pred = model(X_train_batch, training=True)\n",
    "        \n",
    "        # compute loss\n",
    "        loss = loss_fn(y_train_batch, y_pred)\n",
    "        \n",
    "    # back propogation\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    \n",
    "    # monitor performance\n",
    "    loss_val, rmse = float(loss), float(tf.math.sqrt(loss))\n",
    "    print(f'batch {step+1:2d}:  loss={loss_val:7.2f}, RMSE={rmse:7.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gVl44Jq5CApl"
   },
   "source": [
    "## Implement 10 epochs of gradient descent training\n",
    "\n",
    "For every step of gradient descent, printout the MSE, RMSE, epoch index, and batch index.\n",
    "\n",
    "* **hint:** you can call `enumerate(DataLoader)` repeatedly in a `for` loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T12:04:41.532642Z",
     "start_time": "2021-02-23T12:03:21.287590Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "hHtI3TB8ewaF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 ...\n",
      "  -- batch  1:  loss=4175.20, RMSE=64.6158\n",
      "  -- batch  2:  loss=4087.41, RMSE=63.9328\n",
      "  -- batch  3:  loss=4003.14, RMSE=63.2704\n",
      "  -- batch  4:  loss=3919.38, RMSE=62.6049\n",
      "  -- batch  5:  loss=3837.14, RMSE=61.9446\n",
      "  -- batch  6:  loss=3755.84, RMSE=61.2849\n",
      "  -- batch  7:  loss=3673.46, RMSE=60.6091\n",
      "  -- batch  8:  loss=3596.27, RMSE=59.9689\n",
      "  -- batch  9:  loss=3520.07, RMSE=59.3301\n",
      "  -- batch 10:  loss=3476.69, RMSE=58.9635\n",
      "  -- batch 11:  loss=3424.98, RMSE=58.5234\n",
      "  -- batch 12:  loss=3357.76, RMSE=57.9462\n",
      "  -- batch 13:  loss=3275.19, RMSE=57.2292\n",
      "  -- batch 14:  loss=3173.76, RMSE=56.3361\n",
      "  -- batch 15:  loss=3089.35, RMSE=55.5820\n",
      "  -- batch 16:  loss=3005.82, RMSE=54.8254\n",
      "  -- batch 17:  loss=2870.87, RMSE=53.5805\n",
      "  -- batch 18:  loss=2891.85, RMSE=53.7759\n",
      "  -- batch 19:  loss=2786.87, RMSE=52.7908\n",
      "  -- batch 20:  loss=2666.90, RMSE=51.6421\n",
      "epoch  2 ...\n",
      "  -- batch  1:  loss=2675.80, RMSE=51.7281\n",
      "  -- batch  2:  loss=2612.00, RMSE=51.1077\n",
      "  -- batch  3:  loss=2551.14, RMSE=50.5088\n",
      "  -- batch  4:  loss=2490.71, RMSE=49.9070\n",
      "  -- batch  5:  loss=2431.89, RMSE=49.3142\n",
      "  -- batch  6:  loss=2373.75, RMSE=48.7212\n",
      "  -- batch  7:  loss=2315.03, RMSE=48.1147\n",
      "  -- batch  8:  loss=2260.31, RMSE=47.5427\n",
      "  -- batch  9:  loss=2206.60, RMSE=46.9745\n",
      "  -- batch 10:  loss=2178.93, RMSE=46.6790\n",
      "  -- batch 11:  loss=2144.50, RMSE=46.3088\n",
      "  -- batch 12:  loss=2098.18, RMSE=45.8059\n",
      "  -- batch 13:  loss=2039.57, RMSE=45.1616\n",
      "  -- batch 14:  loss=1966.51, RMSE=44.3453\n",
      "  -- batch 15:  loss=1907.14, RMSE=43.6708\n",
      "  -- batch 16:  loss=1848.43, RMSE=42.9933\n",
      "  -- batch 17:  loss=1750.34, RMSE=41.8371\n",
      "  -- batch 18:  loss=1771.92, RMSE=42.0942\n",
      "  -- batch 19:  loss=1697.11, RMSE=41.1959\n",
      "  -- batch 20:  loss=1610.66, RMSE=40.1330\n",
      "epoch  3 ...\n",
      "  -- batch  1:  loss=1622.87, RMSE=40.2848\n",
      "  -- batch  2:  loss=1579.69, RMSE=39.7453\n",
      "  -- batch  3:  loss=1538.77, RMSE=39.2272\n",
      "  -- batch  4:  loss=1498.09, RMSE=38.7052\n",
      "  -- batch  5:  loss=1458.94, RMSE=38.1961\n",
      "  -- batch  6:  loss=1420.13, RMSE=37.6846\n",
      "  -- batch  7:  loss=1381.04, RMSE=37.1623\n",
      "  -- batch  8:  loss=1344.81, RMSE=36.6716\n",
      "  -- batch  9:  loss=1309.49, RMSE=36.1869\n",
      "  -- batch 10:  loss=1294.17, RMSE=35.9745\n",
      "  -- batch 11:  loss=1273.40, RMSE=35.6847\n",
      "  -- batch 12:  loss=1243.81, RMSE=35.2676\n",
      "  -- batch 13:  loss=1204.52, RMSE=34.7062\n",
      "  -- batch 14:  loss=1154.51, RMSE=33.9781\n",
      "  -- batch 15:  loss=1115.21, RMSE=33.3947\n",
      "  -- batch 16:  loss=1076.30, RMSE=32.8070\n",
      "  -- batch 17:  loss=1008.31, RMSE=31.7539\n",
      "  -- batch 18:  loss=1028.66, RMSE=32.0727\n",
      "  -- batch 19:  loss= 978.01, RMSE=31.2732\n",
      "  -- batch 20:  loss= 918.53, RMSE=30.3072\n",
      "epoch  4 ...\n",
      "  -- batch  1:  loss= 931.74, RMSE=30.5244\n",
      "  -- batch  2:  loss= 904.35, RMSE=30.0724\n",
      "  -- batch  3:  loss= 878.60, RMSE=29.6412\n",
      "  -- batch  4:  loss= 852.86, RMSE=29.2037\n",
      "  -- batch  5:  loss= 828.55, RMSE=28.7846\n",
      "  -- batch  6:  loss= 804.24, RMSE=28.3591\n",
      "  -- batch  7:  loss= 779.87, RMSE=27.9262\n",
      "  -- batch  8:  loss= 757.36, RMSE=27.5202\n",
      "  -- batch  9:  loss= 735.64, RMSE=27.1227\n",
      "  -- batch 10:  loss= 728.80, RMSE=26.9963\n",
      "  -- batch 11:  loss= 717.60, RMSE=26.7881\n",
      "  -- batch 12:  loss= 700.15, RMSE=26.4603\n",
      "  -- batch 13:  loss= 675.15, RMSE=25.9837\n",
      "  -- batch 14:  loss= 642.52, RMSE=25.3480\n",
      "  -- batch 15:  loss= 618.07, RMSE=24.8610\n",
      "  -- batch 16:  loss= 593.76, RMSE=24.3672\n",
      "  -- batch 17:  loss= 548.91, RMSE=23.4289\n",
      "  -- batch 18:  loss= 566.31, RMSE=23.7973\n",
      "  -- batch 19:  loss= 533.81, RMSE=23.1044\n",
      "  -- batch 20:  loss= 494.75, RMSE=22.2429\n",
      "epoch  5 ...\n",
      "  -- batch  1:  loss= 506.89, RMSE=22.5142\n",
      "  -- batch  2:  loss= 490.64, RMSE=22.1504\n",
      "  -- batch  3:  loss= 475.50, RMSE=21.8060\n",
      "  -- batch  4:  loss= 460.18, RMSE=21.4518\n",
      "  -- batch  5:  loss= 446.20, RMSE=21.1235\n",
      "  -- batch  6:  loss= 431.93, RMSE=20.7830\n",
      "  -- batch  7:  loss= 417.78, RMSE=20.4397\n",
      "  -- batch  8:  loss= 404.65, RMSE=20.1159\n",
      "  -- batch  9:  loss= 392.22, RMSE=19.8045\n",
      "  -- batch 10:  loss= 390.49, RMSE=19.7608\n",
      "  -- batch 11:  loss= 385.29, RMSE=19.6289\n",
      "  -- batch 12:  loss= 375.94, RMSE=19.3892\n",
      "  -- batch 13:  loss= 360.78, RMSE=18.9942\n",
      "  -- batch 14:  loss= 340.47, RMSE=18.4518\n",
      "  -- batch 15:  loss= 326.29, RMSE=18.0636\n",
      "  -- batch 16:  loss= 312.05, RMSE=17.6651\n",
      "  -- batch 17:  loss= 284.11, RMSE=16.8556\n",
      "  -- batch 18:  loss= 297.48, RMSE=17.2475\n",
      "  -- batch 19:  loss= 277.86, RMSE=16.6692\n",
      "  -- batch 20:  loss= 253.48, RMSE=15.9211\n",
      "epoch  6 ...\n",
      "  -- batch  1:  loss= 263.15, RMSE=16.2219\n",
      "  -- batch  2:  loss= 254.18, RMSE=15.9432\n",
      "  -- batch  3:  loss= 245.91, RMSE=15.6815\n",
      "  -- batch  4:  loss= 237.30, RMSE=15.4047\n",
      "  -- batch  5:  loss= 229.97, RMSE=15.1648\n",
      "  -- batch  6:  loss= 222.12, RMSE=14.9038\n",
      "  -- batch  7:  loss= 214.53, RMSE=14.6469\n",
      "  -- batch  8:  loss= 207.32, RMSE=14.3985\n",
      "  -- batch  9:  loss= 200.72, RMSE=14.1677\n",
      "  -- batch 10:  loss= 201.58, RMSE=14.1977\n",
      "  -- batch 11:  loss= 199.68, RMSE=14.1308\n",
      "  -- batch 12:  loss= 195.28, RMSE=13.9742\n",
      "  -- batch 13:  loss= 186.43, RMSE=13.6539\n",
      "  -- batch 14:  loss= 174.37, RMSE=13.2048\n",
      "  -- batch 15:  loss= 166.85, RMSE=12.9170\n",
      "  -- batch 16:  loss= 159.11, RMSE=12.6138\n",
      "  -- batch 17:  loss= 142.94, RMSE=11.9559\n",
      "  -- batch 18:  loss= 151.93, RMSE=12.3260\n",
      "  -- batch 19:  loss= 141.00, RMSE=11.8743\n",
      "  -- batch 20:  loss= 126.67, RMSE=11.2546\n",
      "epoch  7 ...\n",
      "  -- batch  1:  loss= 133.24, RMSE=11.5429\n",
      "  -- batch  2:  loss= 128.66, RMSE=11.3430\n",
      "  -- batch  3:  loss= 124.47, RMSE=11.1566\n",
      "  -- batch  4:  loss= 119.85, RMSE=10.9474\n",
      "  -- batch  5:  loss= 116.45, RMSE=10.7911\n",
      "  -- batch  6:  loss= 112.37, RMSE=10.6007\n",
      "  -- batch  7:  loss= 108.68, RMSE=10.4251\n",
      "  -- batch  8:  loss= 104.88, RMSE=10.2411\n",
      "  -- batch  9:  loss= 101.66, RMSE=10.0825\n",
      "  -- batch 10:  loss= 103.44, RMSE=10.1704\n",
      "  -- batch 11:  loss= 103.03, RMSE=10.1504\n",
      "  -- batch 12:  loss= 101.38, RMSE=10.0685\n",
      "  -- batch 13:  loss=  96.30, RMSE= 9.8133\n",
      "  -- batch 14:  loss=  89.47, RMSE= 9.4589\n",
      "  -- batch 15:  loss=  86.00, RMSE= 9.2738\n",
      "  -- batch 16:  loss=  82.20, RMSE= 9.0664\n",
      "  -- batch 17:  loss=  73.90, RMSE= 8.5962\n",
      "  -- batch 18:  loss=  78.78, RMSE= 8.8756\n",
      "  -- batch 19:  loss=  73.42, RMSE= 8.5685\n",
      "  -- batch 20:  loss=  65.67, RMSE= 8.1038\n",
      "epoch  8 ...\n",
      "  -- batch  1:  loss=  69.15, RMSE= 8.3158\n",
      "  -- batch  2:  loss=  67.02, RMSE= 8.1863\n",
      "  -- batch  3:  loss=  65.04, RMSE= 8.0650\n",
      "  -- batch  4:  loss=  62.58, RMSE= 7.9108\n",
      "  -- batch  5:  loss=  61.32, RMSE= 7.8309\n",
      "  -- batch  6:  loss=  59.28, RMSE= 7.6995\n",
      "  -- batch  7:  loss=  57.72, RMSE= 7.5975\n",
      "  -- batch  8:  loss=  55.71, RMSE= 7.4642\n",
      "  -- batch  9:  loss=  54.26, RMSE= 7.3663\n",
      "  -- batch 10:  loss=  56.07, RMSE= 7.4878\n",
      "  -- batch 11:  loss=  56.11, RMSE= 7.4905\n",
      "  -- batch 12:  loss=  55.82, RMSE= 7.4712\n",
      "  -- batch 13:  loss=  52.86, RMSE= 7.2705\n",
      "  -- batch 14:  loss=  49.20, RMSE= 7.0140\n",
      "  -- batch 15:  loss=  48.06, RMSE= 6.9323\n",
      "  -- batch 16:  loss=  46.51, RMSE= 6.8198\n",
      "  -- batch 17:  loss=  43.25, RMSE= 6.5767\n",
      "  -- batch 18:  loss=  44.69, RMSE= 6.6850\n",
      "  -- batch 19:  loss=  42.77, RMSE= 6.5400\n",
      "  -- batch 20:  loss=  39.17, RMSE= 6.2590\n",
      "epoch  9 ...\n",
      "  -- batch  1:  loss=  39.99, RMSE= 6.3235\n",
      "  -- batch  2:  loss=  39.10, RMSE= 6.2527\n",
      "  -- batch  3:  loss=  38.23, RMSE= 6.1828\n",
      "  -- batch  4:  loss=  36.83, RMSE= 6.0690\n",
      "  -- batch  5:  loss=  36.64, RMSE= 6.0529\n",
      "  -- batch  6:  loss=  35.60, RMSE= 5.9664\n",
      "  -- batch  7:  loss=  35.11, RMSE= 5.9258\n",
      "  -- batch  8:  loss=  33.96, RMSE= 5.8273\n",
      "  -- batch  9:  loss=  33.35, RMSE= 5.7752\n",
      "  -- batch 10:  loss=  34.80, RMSE= 5.8994\n",
      "  -- batch 11:  loss=  34.79, RMSE= 5.8986\n",
      "  -- batch 12:  loss=  35.10, RMSE= 5.9246\n",
      "  -- batch 13:  loss=  33.26, RMSE= 5.7675\n",
      "  -- batch 14:  loss=  31.45, RMSE= 5.6079\n",
      "  -- batch 15:  loss=  31.59, RMSE= 5.6201\n",
      "  -- batch 16:  loss=  31.27, RMSE= 5.5922\n",
      "  -- batch 17:  loss=  31.16, RMSE= 5.5817\n",
      "  -- batch 18:  loss=  29.96, RMSE= 5.4735\n",
      "  -- batch 19:  loss=  30.09, RMSE= 5.4859\n",
      "  -- batch 20:  loss=  29.04, RMSE= 5.3885\n",
      "epoch 10 ...\n",
      "  -- batch  1:  loss=  27.78, RMSE= 5.2705\n",
      "  -- batch  2:  loss=  27.47, RMSE= 5.2415\n",
      "  -- batch  3:  loss=  27.10, RMSE= 5.2059\n",
      "  -- batch  4:  loss=  26.19, RMSE= 5.1174\n",
      "  -- batch  5:  loss=  26.48, RMSE= 5.1455\n",
      "  -- batch  6:  loss=  25.88, RMSE= 5.0876\n",
      "  -- batch  7:  loss=  25.90, RMSE= 5.0897\n",
      "  -- batch  8:  loss=  25.11, RMSE= 5.0107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -- batch  9:  loss=  24.87, RMSE= 4.9865\n",
      "  -- batch 10:  loss=  25.89, RMSE= 5.0880\n",
      "  -- batch 11:  loss=  25.66, RMSE= 5.0660\n",
      "  -- batch 12:  loss=  26.19, RMSE= 5.1176\n",
      "  -- batch 13:  loss=  24.92, RMSE= 4.9923\n",
      "  -- batch 14:  loss=  24.16, RMSE= 4.9150\n",
      "  -- batch 15:  loss=  24.97, RMSE= 4.9973\n",
      "  -- batch 16:  loss=  25.31, RMSE= 5.0312\n",
      "  -- batch 17:  loss=  27.09, RMSE= 5.2052\n",
      "  -- batch 18:  loss=  24.04, RMSE= 4.9029\n",
      "  -- batch 19:  loss=  25.37, RMSE= 5.0370\n",
      "  -- batch 20:  loss=  25.82, RMSE= 5.0815\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "for epoch in range(epochs):\n",
    "    for step, (X_train_batch, y_train_batch) in enumerate(train_ds):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # forward pass\n",
    "            y_pred = model(X_train_batch, training=True)\n",
    "\n",
    "            # compute loss\n",
    "            loss = loss_fn(y_train_batch, y_pred)\n",
    "\n",
    "        # back propogation\n",
    "        grads = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        # monitor performance\n",
    "        loss_val, rmse = float(loss), float(tf.math.sqrt(loss))\n",
    "        if (step==0):\n",
    "            print(f'epoch {epoch+1:2d} ...')\n",
    "        print(f'  -- batch {step+1:2d}:  loss={loss_val:7.2f}, RMSE={rmse:7.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IlrLCc3SCmuk"
   },
   "source": [
    "Copyright 2020 CounterFactual.AI LLC. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Solution_PyTorch_Dataset_Dataloader.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
