{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Demo_Autograd_GPU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxHo2YuJwuXg"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osipov/edu/blob/master/tf0/Demo_Autograd_GPU.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBOV9uikT7uc"
      },
      "source": [
        "# Automatic differentiation in TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQw_9onZT7ud"
      },
      "source": [
        "Simply add `trainable=True` to the tensors you want to calculate the gradients for. TensorFlow libraries such as `keras` track gradients automatically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul--BM_FT7ue"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPqv0bLTT7ud"
      },
      "source": [
        "## Autodiff is enabled in `tf.Variable` by default"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzXErpFaT7ui"
      },
      "source": [
        "x = tf.Variable(2.)\n",
        "x, x.trainable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jTdbMw9T7ul"
      },
      "source": [
        "y = tf.Variable(3., trainable = False)\n",
        "y, y.trainable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVj1vknvT7vF"
      },
      "source": [
        "## Tensorflow will not track the gradient if you don't use `with tf.GradientTape() as tape:`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5Dj-jK9T7uo"
      },
      "source": [
        "with tf.GradientTape(persistent=True) as tape:\r\n",
        "  z = x ** y #x^3 for x = 2, dz_dx = 3 * (x^2) = 3 * 4 = 12 \r\n",
        "\r\n",
        "dz_dx, dz_dy = tape.gradient(z, [x, y])\r\n",
        "dz_dx, dz_dy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh2sr7KyT7vO"
      },
      "source": [
        "<html><h2><font style=\"color:red\">GPU support is required</font> to demonstrate high performance tensor operations</h2></html>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cLNyRu7T7vO"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('In Google Colab select the Runtime â†’ \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_M0f-qtT7vR"
      },
      "source": [
        "When CUDA drivers are installed on the device, the following returns the CUDA capability profile documented by nVidia. For the capability profile v7.0 check out https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capability-7-x for information about the capability profile include the expected count of the Arithmetic Logic Units (ALUs).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IL5gDxjT7vS"
      },
      "source": [
        "import torch as pt\n",
        "pt.cuda.get_device_capability(pt.device(\"cuda\")) if pt.cuda.is_available() else None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_qYuE5yT7vU"
      },
      "source": [
        "## Tensorflow tensors are automatically created on a GPU if one is available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXed51SZT7vX"
      },
      "source": [
        "import timeit\n",
        "\n",
        "MAX_SIZE = 28\n",
        "sizes = [2 ** i for i in range(MAX_SIZE)]\n",
        "\n",
        "def benchmark_cpu_gpu(n):\n",
        "  for device in [\"/CPU:0\", \"/GPU:0\"]:\n",
        "    with tf.device(device):\n",
        "      for size in sizes:\n",
        "        a = tf.random.normal([size], 0., 1.)\n",
        "        b = tf.random.normal([size], 0., 1.)\n",
        "        yield timeit.timeit(lambda: a + b, number = n)\n",
        "\n",
        "measurements = list(benchmark_cpu_gpu(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJbkEwlqT7vb"
      },
      "source": [
        "## Measure the performance ratio CPU / GPU, higher is faster GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-ln3pu6T7vb"
      },
      "source": [
        "cpu = measurements[:MAX_SIZE]\n",
        "gpu = measurements[MAX_SIZE:]\n",
        "ratios = [cpu[i] / gpu[i] for i in range(len(cpu))]\n",
        "ratios"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F4paf4ET7vf"
      },
      "source": [
        "## When adding tensors with `16,384` values and more, GPU can be up to `3000x` faster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3WKlooPT7vf"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rc('xtick', labelsize=20)\n",
        "plt.rc('ytick', labelsize=20)\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(sizes, ratios)\n",
        "plt.xscale(\"log\", basex=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGHWIcw9T7vh"
      },
      "source": [
        "## GPU performance on tensors with `8,192`  or fewer elements is on par with CPUs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Vnu-pY-T7vi"
      },
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "\n",
        "plt.plot(sizes[:17], ratios[:17])\n",
        "plt.xscale(\"log\", basex=2);\n",
        "\n",
        "plt.rc('xtick', labelsize=20)\n",
        "plt.rc('ytick', labelsize=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBI5VGQNUI6m"
      },
      "source": [
        "Copyright 2021 CounterFactual.AI LLC. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    }
  ]
}